{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar & Translation scheme\n",
    "\n",
    "entrada —> sent {sent.s->evaluar()} entrada  <br>\n",
    "        —> épsilon  <br>\n",
    "\n",
    "sent —> PRINT exp ‘;’    {sent.s := new NodoPrint(expr.s);} <br>\n",
    "     —> ID ASIGN exp ‘;’ {sent.s := new NodoAsign(ID.lexval, expr.s);} <br>\n",
    "\n",
    "exp  —> exp OR term {exp.s := new NodoOR(exp1.s, term.s)}<br>\n",
    "     —> term {exp.s = term.s} <br>\n",
    "\n",
    "term —> term AND fact {term.s := new NodoAND(term1.s, fact.s)}<br>\n",
    "     —> fact {term.s = fact.s}<br>\n",
    "\n",
    "fact —> NOT fact {fact.s := new NodoNOT(fatc1.s)}<br>\n",
    "     —> ‘(‘ exp ‘)’ {fact.s := exp.s}<br>\n",
    "     —> ID {fact.s := new NodoID(Id.lexval)}<br>\n",
    "     —> TRUE {fact.s := new NodoTrue()}<br>\n",
    "     —> FALSE {fact.s := new NodoFalse()}<br>\n",
    "\n",
    "# Grammar adaptation\n",
    "\n",
    "entrada —> sent {sent.s->evaluar()} entrada  <br>\n",
    "        —> épsilon  <br>\n",
    "\n",
    "sent —> PRINT exp ‘;’    {sent.s := new NodoPrint(expr.s);} <br>\n",
    "     —> ID ASIGN exp ‘;’ {sent.s := new NodoAsign(ID.lexval, expr.s);} <br>\n",
    "\n",
    "expr -> term {expr'.h := term.s;} expr' {expr.s := expr'.s;} <br>\n",
    "\n",
    "expr' -> OR term {expr'1.h := new NodoOR(expr'.h, term.s);} expr'1 {expr'.s := expr'1.s;} <br>\n",
    "      -> epsilon    {expr'.s := expr'.h;} <br>\n",
    "\n",
    "term -> fact {term'.h := fact.s;} term' {term.s := term'.s;} <br>\n",
    "\n",
    "term' -> AND fact {term'1.h := new NodoConj(term'.h, fact.s);} term'1 {term'.s := term'1.s;} <br>\n",
    "      -> epsilon    {term'.s := term'.h;} <br>\n",
    "\n",
    "fact —> NOT fact {fact.s := new NodoNOT(fatc1.s)}<br>\n",
    "     —> ‘(‘ exp ‘)’ {fact.s := exp.s}<br>\n",
    "     —> ID {fact.s := new NodoID(Id.lexval)}<br>\n",
    "     —> TRUE {fact.s := new NodoTrue()}<br>\n",
    "     —> FALSE {fact.s := new NodoFalse()}<br>\n",
    "\n",
    "# First and Follow sets\n",
    "\n",
    "First(fact)    = {NOT, '(', ID, VERDADERO, FALSO}<br>\n",
    "First(term')   = {AND, epsilon}<br>\n",
    "First(term)    = First(fact) = {NOT, '(', ID, VERDADERO, FALSO}<br>\n",
    "First(expr')   = {OR, epsilon}<br>\n",
    "First(exp)     = First(term) = First(fact) = {NOT, '(', ID, VERDADERO, FALSO}<br>\n",
    "First(sent)    = {PRINT, ID}<br>\n",
    "First(entrada) = First(sent) U {epsilon} = {PRINT, ID, epsilon}<br>\n",
    "\n",
    "Follow(entrada) = {EOF}<br>\n",
    "Follow(sent)    = First(Entrada) U Follow(Entrada) = {PRINT, ID, EOF}<br>\n",
    "Follow(expr)    = {';', ')'}<br>\n",
    "Follow(expr')   = Follow(exp) = Follow(exp') = {';', ')'}<br>\n",
    "Follow(term)    = First(expr') U Follow(expr) U Follow(expr') = {OR, ';', ')'}<br>\n",
    "Follow(term')   = Follow(term) U Follow(term') = {OR, ';'}<br>\n",
    "Follow(fact)    = First(term') U Follow(term) U Follow(term') = {AND, OR, ';', ')'}<br>\n",
    "\n",
    "# Bottom - up implementation\n",
    "\n",
    "## Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer\n",
    "\n",
    "ta = None\n",
    "ind = 0\n",
    "toks = None\n",
    "tokenlist = None\n",
    "\n",
    "class CalcLexer(Lexer):\n",
    "    tokens = {ID, NOT, OR, AND, TRUE, FALSE, PRINT, ASIG}\n",
    "    ignore = ' \\t'\n",
    "    literals = { ';', '(', ')'}\n",
    "\n",
    "    # Regular expression rules for tokens\n",
    "    ASIG          = r':='\n",
    "    ID            = r'[a-zA-Z_][a-zA-Z0-9_]*'\n",
    "    ID['or']      = OR\n",
    "    ID['and']     = AND\n",
    "    ID['not']     = NOT\n",
    "    ID['true']    = TRUE\n",
    "    ID['false']   = FALSE\n",
    "    ID['print']   = PRINT\n",
    "    \n",
    "    @_(r'\\n+')\n",
    "    def newline(self, t):\n",
    "        self.lineno += t.value.count('\\n')\n",
    "\n",
    "    def error(self, t):\n",
    "        print(\"Illegal character '%s'\" % t.value[0])\n",
    "        self.index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = {}\n",
    "\n",
    "class Nodo:\n",
    "    def evaluar():\n",
    "        pass\n",
    "    def toStr():\n",
    "        pass\n",
    "#fin de la clase abstracta Nodo\n",
    "\n",
    "class NodoTrue(Nodo):\n",
    "    def evaluar(self): \n",
    "        return True\n",
    "    def toStr(): \n",
    "        return \"true\"\n",
    "#fin de la clase NodoTrue\n",
    "\n",
    "class NodoFalse(Nodo):\n",
    "    def evaluar(self): \n",
    "        return False\n",
    "    def toStr(): \n",
    "        return \"false\"\n",
    "#fin de la clase NodoFalse\n",
    "\n",
    "class NodoId(Nodo):\n",
    "    def __init__(self, n):\n",
    "        self.nombre = n\n",
    "    def evaluar(self): \n",
    "        global tabla\n",
    "        return  tabla[self.nombre]\n",
    "    def toStr(): \n",
    "        return \"ID(\" + self.nombre + \")\"\n",
    "#fin de la clase NodoId\n",
    "\n",
    "class NodoNOT(Nodo):\n",
    "    def __init__(self, c):\n",
    "        self.comp = c\n",
    "    def evaluar(self):\n",
    "        return  not self.comp.evaluar()\n",
    "    def toStr(): \n",
    "        return \"NO(\" + self.comp.toStr() + \")\"\n",
    "#fin de la clase NodoNOT\n",
    "\n",
    "class NodoAND(Nodo):\n",
    "    def __init__(self, i, d):\n",
    "        self.izq = i\n",
    "        self.der = d\n",
    "    def evaluar(self):\n",
    "        return  self.izq.evaluar() and self.der.evaluar()\n",
    "    def toStr(): \n",
    "        return \"and(\" + self.izq.toStr() + \",\" + self.der.toStr() + \")\"\n",
    "#fin de la clase NodoAND\n",
    "\n",
    "class NodoOR(Nodo):\n",
    "    def __init__(self, i, d):\n",
    "        self.izq = i\n",
    "        self.der = d\n",
    "    def evaluar(self):\n",
    "        return  self.izq.evaluar() or self.der.evaluar()\n",
    "    def toStr(): \n",
    "        return \"or(\" + self.izq.toStr() + \",\" + self.der.toStr() + \")\"\n",
    "#fin de la clase NodoOR\n",
    "\n",
    "class NodoAsign(Nodo): \n",
    "    def __init__(self, n, e):\n",
    "        self.nombre = n\n",
    "        self.expr = e\n",
    "    def evaluar(self):\n",
    "        global tabla\n",
    "        tabla[self.nombre] = self.expr.evaluar()\n",
    "        return tabla[self.nombre]\n",
    "    def toStr():\n",
    "        return \"tabla[\" + self.nombre + \"]=\" + self.expr.toStr()\n",
    "#fin de la clase NodoAsign\n",
    "\n",
    "class NodoPrint(Nodo):\n",
    "    def __init__(self, e):\n",
    "        self.expr = e\n",
    "    def evaluar(self):\n",
    "        temporal = self.expr.evaluar()\n",
    "        print(\"resultado = \", int(temporal))\n",
    "        return temporal\n",
    "    def toStr(): \n",
    "        return \"print(\" + self.expr.toStr() + \")\"\n",
    "#fin de la clase NodoPrint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yyerror(msj):\n",
    "    print(\"Error sistactico\", msj)\n",
    "#fin de yyerror() \n",
    "\n",
    "def cuadra(obj): \n",
    "    global ta, ind, tokenlist\n",
    "    if ta.type == obj:\n",
    "        #print(\"cuadro ta = \", ta.value) \n",
    "        ind += 1\n",
    "        if ind < len(tokenlist):\n",
    "            ta = tokenlist[ind]\n",
    "            #print(\"==> nuevo ta = \", ta.value)\n",
    "    else:\n",
    "        yyerror(\"en cuadra\"); \n",
    "#fin de cuadra() \n",
    "\n",
    "def fact():\n",
    "    global ta, toks\n",
    "    if ta.type == toks[4]: #NOT\n",
    "        cuadra(\"NOT\")\n",
    "        fact1_s = fact()\n",
    "        return NodoNOT(fact1_s)\n",
    "    else:\n",
    "        if ta.type == toks[3]: #ID\n",
    "            IDlexval = ta.value\n",
    "            cuadra(\"ID\")\n",
    "            return NodoId(IDlexval)\n",
    "        else: \n",
    "            if ta.type == toks[7]: #true\n",
    "                cuadra(\"TRUE\")\n",
    "                return NodoTrue()\n",
    "            else:\n",
    "                if ta.type == toks[2]: #false\n",
    "                    cuadra(\"FALSE\")\n",
    "                    return NodoFalse()\n",
    "                else:\n",
    "                    if ta.value == '(':\n",
    "                        cuadra('(')\n",
    "                        expr_s = expr()\n",
    "                        cuadra(')')\n",
    "                        return expr_s\n",
    "                    else:\n",
    "                        error(\"en fact\");\n",
    "#fin de fact()\n",
    "\n",
    "def term_prima(term_prima_h):\n",
    "    global ta, toks\n",
    "    if ta.type == toks[0]: #AND\n",
    "        cuadra(\"AND\")\n",
    "        fact_s = fact()\n",
    "        term_prima_1_h = NodoAND(term_prima_h, fact_s)\n",
    "        return term_prima(term_prima_1_h)\n",
    "    else:\n",
    "        if ta.value == ';' or ta.value == ')' or ta.type == toks[5]:\n",
    "            return term_prima_h;\n",
    "        else:\n",
    "            yyerror(\"en term_prima\");\n",
    "#fin de term_prima()\n",
    "\n",
    "def term():\n",
    "    global ta, toks\n",
    "    if ta.type == toks[4] or ta.type == toks[7] or ta.type == toks[2] or ta.type == toks[3] or ta.value == '(':\n",
    "        facts_s = fact()\n",
    "        term_prima_h = facts_s\n",
    "        term_prima_s = term_prima(term_prima_h)\n",
    "        return term_prima_s\n",
    "    else:\n",
    "        yyerror(\"en term\");\n",
    "#fin de term()\n",
    "\n",
    "def expr_prima(expr_prima_h):\n",
    "    global ta, toks\n",
    "    if ta.type == toks[5]: #OR\n",
    "        cuadra(\"OR\")\n",
    "        term_s = term()\n",
    "        expr_prima_1_h = NodoOR(expr_prima_h, term_s)\n",
    "        return expr_prima(expr_prima_1_h)\n",
    "    else:\n",
    "        if ta.value == ';' or ta.value == ')':\n",
    "            return expr_prima_h\n",
    "        else:\n",
    "            yyerror(\"en expr_prima\")\n",
    "#fin de expr_prima()\n",
    "\n",
    "def expr():\n",
    "    global ta, toks\n",
    "    if ta.type == toks[4] or ta.type == toks[7] or ta.type == toks[2] or ta.type == toks[3] or ta.value == '(':\n",
    "        term_s = term()\n",
    "        expr_prima_h = term_s\n",
    "        expr_prima_s = expr_prima(expr_prima_h)\n",
    "        return expr_prima_s\n",
    "    else:\n",
    "        yyerror(\"en expr\")\n",
    "#fin de expr()\n",
    "\n",
    "\n",
    "def sent():\n",
    "    global ta, toks\n",
    "    if ta.type == toks[6]: #PRINT\n",
    "        cuadra(\"PRINT\")\n",
    "        expr_s = expr()\n",
    "        cuadra(';')\n",
    "        return NodoPrint(expr_s)\n",
    "    else:\n",
    "        if ta.type == toks[3]: #ID\n",
    "            IDlexval = ta.value\n",
    "            cuadra(\"ID\")\n",
    "            cuadra(\"ASIG\")\n",
    "            expr_s = expr()\n",
    "            cuadra(';')\n",
    "            return NodoAsign(IDlexval, expr_s)\n",
    "        else:\n",
    "            yyerror(\"en sent\")\n",
    "# fin de sent()\n",
    "\n",
    "def entrada(): \n",
    "    global ta, toks, tokenlist\n",
    "    if ta.type == toks[6] or ta.type == toks[3]:\n",
    "        sent_s = sent()\n",
    "        sent_s.evaluar()\n",
    "        entrada()\n",
    "    else: \n",
    "        if ind < len(tokenlist):  #fin de la entrada\n",
    "            yyerror(\"En entrada\")\n",
    "#fin de entrada()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    global ta, toks, tokenlist, ind\n",
    "    lexer = CalcLexer()\n",
    "    toks = CalcLexer.tokens\n",
    "    toks = sorted(toks)\n",
    "    while True:\n",
    "        try:\n",
    "            data = input('data type list > ')\n",
    "        except EOFError:\n",
    "            break\n",
    "        if data:\n",
    "            tokenlist = list(lexer.tokenize(data))\n",
    "            ta = tokenlist[ind]\n",
    "            entrada()\n",
    "        ind = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
