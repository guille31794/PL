{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Design translation scheme (offset parameters Pascal style. That is, the parameters are put on the stack from left to right). Calculate the first and follow sets. Develop this grammar using SLY.\n",
    "<br>\n",
    "\n",
    "Grammar:\n",
    "Def   -> ID ‘(‘ Tipo ID Resto’)’ <br>\n",
    "Resto -> ‘,’ Tipo ID Resto <br>\n",
    "Resto -> epsilon <br>\n",
    "Tipo -> INT  <br>\n",
    "Tipo -> CHAR  <br>\n",
    "Tipo -> FLOAT <br>\n",
    "\n",
    "\n",
    "\n",
    " <br>\n",
    "Example:  <br>\n",
    " <br>\n",
    "Input : f(int a, float b, char c) <br>\n",
    "Output: Offset de c = 4 <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Offset de b = 4 + sizeof(char)  <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Offset de a = 4 + sizeof(char) + sizeof(float) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ascending Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funcion > f(int a,float b,char c)\n",
      "Offset de c=4\n",
      "Offset de b=4 + sizeof(char)\n",
      "Offset de a= 4 + sizeof(char) + sizeof(float)\n"
     ]
    }
   ],
   "source": [
    "from sly import Lexer,Parser \n",
    "\n",
    "class Seminario2LEX(Lexer):\n",
    "    \n",
    "    # Set of token names\n",
    "    tokens = {ID,CHAR,INT,FLOAT}\n",
    "    \n",
    "    ignore = ' \\t'\n",
    "    \n",
    "    literals = {'(',')',','}\n",
    "    \n",
    "    ID = r'[a-zA-Z_][a-zA-Z0-9]*'\n",
    "    ID['int'] = INT\n",
    "    ID['float'] = FLOAT\n",
    "    ID['char'] = CHAR\n",
    "    \n",
    "    \n",
    "    \n",
    "class Seminario2PAR(Parser):\n",
    "    \n",
    "    tokens = Seminario2LEX.tokens\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.names = {}\n",
    "        \n",
    "    @_('ID \"(\" Tipo ID Resto \")\"')\n",
    "    def Def(self,p):\n",
    "        print(\"Offset de \" + p.ID1 + \" = \" + p.Resto)\n",
    "    \n",
    "        \n",
    "    @_('\",\" Tipo ID Resto')\n",
    "    def Resto(self,p):        \n",
    "        print(\"Offset de \" + p.ID + \"=\" + p.Resto)     \n",
    "        return p.Resto + ' + ' + p.Tipo\n",
    "    \n",
    "    @_(' ')\n",
    "    def Resto(self,p):\n",
    "        return \"4\"\n",
    "        \n",
    "    @_('INT')\n",
    "    def Tipo(self,p):\n",
    "        return \"sizeof(int)\"\n",
    "\n",
    "    @_('FLOAT')\n",
    "    def Tipo(self,p):\n",
    "        return \"sizeof(float)\"\n",
    "        \n",
    "    @_('CHAR')\n",
    "    def Tipo(self,p):\n",
    "        return \"sizeof(char)\"\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    lexer = Seminario2LEX()\n",
    "    parser = Seminario2PAR()\n",
    "    while True:\n",
    "        try:\n",
    "            text = input('funcion > ')\n",
    "        except EOFError:\n",
    "            break\n",
    "        if text:\n",
    "            parser.parse(lexer.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descending Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type list > f(int a)\n",
      "cuadro ta => f\n",
      "nuevo ta => (\n",
      "cuadro ta => (\n",
      "nuevo ta => int\n",
      "cuadro ta => int\n",
      "nuevo ta => a\n",
      "cuadro ta => a\n",
      "nuevo ta => )\n",
      "Error sistactico Error en Resto\n",
      "cuadro ta => )\n",
      "Offset de  a  =  None\n"
     ]
    }
   ],
   "source": [
    "from sly import Lexer\n",
    "\n",
    "ta = None\n",
    "ind = 0\n",
    "toks = None\n",
    "tokenlist = None\n",
    "\n",
    "\n",
    "class Seminario2LEX(Lexer):\n",
    "    \n",
    "    # Set of token names\n",
    "    tokens = {ID,CHAR,INT,FLOAT}\n",
    "            # CHAR FLOAT ID INT\n",
    "    \n",
    "    ignore = ' \\t'\n",
    "    \n",
    "    literals = {'(',')',','}\n",
    "    \n",
    "    ID = r'[a-zA-Z_][a-zA-Z0-9]*'\n",
    "    ID['int'] = INT\n",
    "    ID['float'] = FLOAT\n",
    "    ID['char'] = CHAR\n",
    "    \n",
    "    \n",
    "def yyerror(msj):\n",
    "    print(\"Error sistactico\", msj)\n",
    "#fin de yyerror() \n",
    "\n",
    "                \n",
    "def Tipo():\n",
    "    global ta\n",
    "    if ta.type == toks[3]:\n",
    "        cuadra(\"INT\")\n",
    "        return \"sizeof(int)\"\n",
    "    else:\n",
    "        if ta.type == toks[1]:\n",
    "            cuadra(\"FLOAT\")\n",
    "            return \"sizeof(float)\"\n",
    "        else:\n",
    "            if ta.type == toks[0]:\n",
    "                cuadra(\"CHAR\")\n",
    "                return \"sizeof(char)\"\n",
    "            else:\n",
    "                yyerror(\"Error en Tipo\")\n",
    "# Fin Tipo\n",
    "    \n",
    "    \n",
    "def Resto():\n",
    "    if ta.value == ',':\n",
    "        cuadra(',')\n",
    "        tipo = Tipo()\n",
    "        IDVAL = ta.value\n",
    "        cuadra(\"ID\")\n",
    "        resto1_s = Resto()\n",
    "        print(\"Offset de \",IDVAL,\" = \",resto1_s)\n",
    "        return resto1_s + \" + \" + tipo\n",
    "    else:\n",
    "        if ta.value == ')':\n",
    "            return \"4\"\n",
    "        else:\n",
    "            yyerror(\"Error en Resto\")\n",
    "# Fin Resto\n",
    "\n",
    "            \n",
    "        \n",
    "def Def():\n",
    "    global ta, toks\n",
    "    if ta.type == toks[2]:\n",
    "        cuadra(\"ID\")\n",
    "        cuadra('(')\n",
    "        tipo = Tipo()\n",
    "        IDVAL = ta.value\n",
    "        cuadra(\"ID\")\n",
    "        resto1_s = Resto()\n",
    "        cuadra(')')\n",
    "        print(\"Offset de \",IDVAL,\" = \",resto1_s)\n",
    "    else:\n",
    "        if ind < len(tokenlist):  #fin de la entrada\n",
    "            yyerror(\"en Def\")            \n",
    "# Fin Def\n",
    "   \n",
    "\n",
    "    \n",
    "def cuadra(obj):\n",
    "    global ta,ind,tokenlist\n",
    "    if ta.type == obj:\n",
    "        print(\"cuadro ta =>\" ,ta.value)\n",
    "        ind += 1\n",
    "        if ind < len(tokenlist):\n",
    "            ta = tokenlist[ind]\n",
    "            print(\"nuevo ta =>\",ta.value)\n",
    "    else:\n",
    "        yyerror(\"Error en cuadra\")\n",
    "# Fin Cuadra\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    lex = Seminario2LEX()\n",
    "    toks = Seminario2LEX.tokens\n",
    "    toks = sorted(toks)\n",
    "    while True:\n",
    "        try:\n",
    "            data = input('data type list > ')\n",
    "        except EOFError:\n",
    "            break\n",
    "        if data:\n",
    "            tokenlist = list(lex.tokenize(data))\n",
    "            ta = tokenlist[ind]\n",
    "            Def()\n",
    "        ind = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
