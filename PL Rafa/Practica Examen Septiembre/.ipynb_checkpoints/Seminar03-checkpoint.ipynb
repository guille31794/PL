{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Design translation scheme (offset parameters Pascal style. That is, the parameters are put on the stack from left to right). Calculate the first and follow sets. Develop this grammar using SLY.\n",
    "<br>\n",
    "\n",
    "Grammar:\n",
    "Def   -> ID ‘(‘ Tipo ID Resto’)’ <br>\n",
    "Resto -> ‘,’ Tipo ID Resto <br>\n",
    "Resto -> epsilon <br>\n",
    "Tipo -> INT  <br>\n",
    "Tipo -> CHAR  <br>\n",
    "Tipo -> FLOAT <br>\n",
    "\n",
    "\n",
    "\n",
    " <br>\n",
    "Example:  <br>\n",
    " <br>\n",
    "Input : f(int a, float b, char c) <br>\n",
    "Output: Offset de c = 4 <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Offset de b = 4 + sizeof(char)  <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Offset de a = 4 + sizeof(char) + sizeof(float) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funcion > f(int a,float b,char c)\n",
      "Offset de c=4\n",
      "Offset de b=4 + sizeof(char)\n",
      "Offset de a= 4 + sizeof(char) + sizeof(float)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from sly import Lexer,Parser \n",
    "\n",
    "class Seminario2LEX(Lexer):\n",
    "    \n",
    "    # Set of token names\n",
    "    tokens = {ID,CHAR,INT,FLOAT}\n",
    "    \n",
    "    ignore = ' \\t'\n",
    "    \n",
    "    literals = {'(',')',','}\n",
    "    \n",
    "    ID = r'[a-zA-Z_][a-zA-Z0-9]*'\n",
    "    ID['int'] = INT\n",
    "    ID['float'] = FLOAT\n",
    "    ID['char'] = CHAR\n",
    "    \n",
    "    \n",
    "    \n",
    "class Seminario2PAR(Parser):\n",
    "    \n",
    "    tokens = Seminario2LEX.tokens\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.names = {}\n",
    "        \n",
    "    @_('ID \"(\" Tipo ID Resto \")\"')\n",
    "    def Def(self,p):\n",
    "        print(\"Offset de \" + p.ID1 + \" = \" + p.Resto)\n",
    "    \n",
    "        \n",
    "    @_('\",\" Tipo ID Resto')\n",
    "    def Resto(self,p):        \n",
    "        print(\"Offset de \" + p.ID + \"=\" + p.Resto)     \n",
    "        return p.Resto + ' + ' + p.Tipo\n",
    "    \n",
    "    @_(' ')\n",
    "    def Resto(self,p):\n",
    "        return \"4\"\n",
    "        \n",
    "    @_('INT')\n",
    "    def Tipo(self,p):\n",
    "        return \"sizeof(int)\"\n",
    "\n",
    "    @_('FLOAT')\n",
    "    def Tipo(self,p):\n",
    "        return \"sizeof(float)\"\n",
    "        \n",
    "    @_('CHAR')\n",
    "    def Tipo(self,p):\n",
    "        return \"sizeof(char)\"\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    lexer = Seminario2LEX()\n",
    "    parser = Seminario2PAR()\n",
    "    while True:\n",
    "        try:\n",
    "            text = input('funcion > ')\n",
    "        except EOFError:\n",
    "            break\n",
    "        if text:\n",
    "            parser.parse(lexer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
