{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Design translation scheme (offset parameters Pascal style. That is, the parameters are put on the stack from left to right). Calculate the first and follow sets. Develop this grammar using SLY.\n",
    "\n",
    "Grammar:\n",
    "Def   -> ID ‘(‘ Tipo ID Resto’)’ <br>\n",
    "Resto -> ‘,’ Tipo ID Resto <br>\n",
    "Resto -> epsilon <br>\n",
    "Tipo -> INT  <br>\n",
    "Tipo -> CHAR  <br>\n",
    "Tipo -> FLOAT <br>\n",
    " <br>\n",
    "Example:  <br>\n",
    " <br>\n",
    "Input : f(int a, float b, char c) <br>\n",
    "Output: Offset de c = 4 <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Offset de b = 4 + sizeof(char)  <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Offset de a = 4 + sizeof(char) + sizeof(float) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation scheme\n",
    "\n",
    "Def   -> ID ‘(‘ Tipo ID Resto’)’ {escribe(\"offset de\", ID.lexval, \"= \", Resto.s)}<br>\n",
    "Resto -> ‘,’ Tipo ID Resto {Resto.s = Resto1.s + \"+\" + Tipo.s; escribe(\"offset de \", Id.lexval, \"=\", Resto1.s)} <br>\n",
    "Resto -> epsilon <br>\n",
    "Tipo -> INT  {Tipo.s = \"sizeof(int)\"} <br>\n",
    "Tipo -> CHAR {Tipo.s = \"sizeof(char)\"} <br>\n",
    "Tipo -> FLOAT {Tipo.s = \"sizeof(float)\"} <br>\n",
    " <br> \n",
    " \n",
    "## First and follow sets\n",
    "\n",
    "First(Tipo) = {INT, FLOAT, CHAR} <br>\n",
    "First(Resto) = {',', epsilon}<br>\n",
    "First(Def) = {ID}<br>\n",
    "<br>\n",
    "Follow(Def) = {EOF}<br>\n",
    "Follow(Resto) = {')'} U Follow(Resto) = {')'}<br>\n",
    "Follow(Tipo) = {ID}<br>\n",
    "\n",
    "## Top-down implementation using SLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer, Parser\n",
    "\n",
    "ta = None\n",
    "ind = 0\n",
    "toks = None\n",
    "tokenlist = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcLexer(Lexer):\n",
    "    tokens = {ID, CHAR, INT, FLOAT}\n",
    "    ignore = ' \\t'\n",
    "    literals = { ',', '(', ')'}\n",
    "\n",
    "    # Regular expression rules for tokens\n",
    "    ID            = r'[a-zA-Z_][a-zA-Z0-9_]*'\n",
    "    ID['char']    = CHAR\n",
    "    ID['int']     = INT\n",
    "    ID['float']   = FLOAT\n",
    "    \n",
    "    @_(r'\\n+')\n",
    "    def newline(self, t):\n",
    "        self.lineno += t.value.count('\\n')\n",
    "\n",
    "    def error(self, t):\n",
    "        print(\"Illegal character '%s'\" % t.value[0])\n",
    "        self.index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcParser(Parser):\n",
    "    tokens = CalcLexer.tokens\n",
    "\n",
    "    def __init__(self):\n",
    "        self.names = { }\n",
    "\n",
    "    @_('ID \"(\" Tipo ID Resto \")\"')\n",
    "    def Def(self, p):\n",
    "        print(\"offset de\", p.ID1, \" = \", p.Resto)\n",
    "    \n",
    "    @_('\",\" Tipo ID Resto')\n",
    "    def Resto(self, p):\n",
    "        print(\"offset de\", p.ID, \" = \", p.Resto) \n",
    "        return p.Resto + ' + ' + p.Tipo\n",
    "    \n",
    "    @_(' ')\n",
    "    def Resto(self, p):\n",
    "        return '4'\n",
    "    \n",
    "    @_('INT')\n",
    "    def Tipo(self, p):\n",
    "        return \"sizeof(int)\"\n",
    "    \n",
    "    @_('FLOAT')\n",
    "    def Tipo(self, p):\n",
    "        return \"sizeof(float)\"\n",
    "    \n",
    "    @_('CHAR')\n",
    "    def Tipo(self, p):\n",
    "        return \"sizeof(char)\"\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    lexer = CalcLexer()\n",
    "    parser = CalcParser()\n",
    "    while True:\n",
    "        try:\n",
    "            text = input('data type list > ')\n",
    "        except EOFError:\n",
    "            break\n",
    "        if text:\n",
    "            parser.parse(lexer.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom - up implementation\n",
    "\n",
    "### Lexer\n",
    "\n",
    "The lexer is the same that top-dowm implementation.\n",
    "\n",
    "### Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yyerror(msj):\n",
    "    print(\"Error sistactico\", msj)\n",
    "#fin de yyerror() \n",
    "\n",
    "def cuadra(obj): \n",
    "    global ta, ind, tokenlist\n",
    "    if ta.type == obj:\n",
    "        #print(\"cuadro ta = \", ta.value) \n",
    "        ind += 1\n",
    "        if ind < len(tokenlist):\n",
    "            ta = tokenlist[ind]\n",
    "            #print(\"==> nuevo ta = \", ta.value)\n",
    "    else:\n",
    "        yyerror(\"en cuadra\"); \n",
    "#fin de cuadra() \n",
    "\n",
    "def Tipo():\n",
    "    global ta\n",
    "    if ta.type == toks[3]:\n",
    "        cuadra(\"INT\")\n",
    "        return \"sizeof(int)\"\n",
    "    else: \n",
    "        if ta.type == toks[1]:\n",
    "            cuadra(\"FLOAT\") \n",
    "            return \"sizeof(float)\"\n",
    "        else:\n",
    "            if ta.type == toks[0]:\n",
    "                cuadra(\"CHAR\") \n",
    "                return \"sizeof(char)\"\n",
    "            else: \n",
    "                yyerror(\"en Tipo\"); \n",
    "#fin Tipo()\n",
    "\n",
    "def Resto():\n",
    "    global ta\n",
    "    if ta.value == ',':\n",
    "        cuadra(',')\n",
    "        tipo_s = Tipo()\n",
    "        IDlexval = ta.value\n",
    "        cuadra(\"ID\")\n",
    "        resto1_s = Resto()\n",
    "        print(\"offset de\", IDlexval, \" = \", resto1_s) \n",
    "        return resto1_s + ' + ' + tipo_s\n",
    "    else:\n",
    "        if ta.value == ')': #Resto -> epsilon\n",
    "            return '4'\n",
    "        else:\n",
    "            yyerror(\"en Resto\");\n",
    "#fin de Resto()\n",
    "\n",
    "def Def():\n",
    "    global ta, toks, tokenlist\n",
    "    if ta.type == toks[2]: #ID\n",
    "        cuadra(\"ID\")\n",
    "        cuadra('(')\n",
    "        tipo_s = Tipo()\n",
    "        IDlexval = ta.value\n",
    "        cuadra(\"ID\")\n",
    "        resto1_s = Resto()\n",
    "        cuadra(')')\n",
    "        print(\"offset de\", IDlexval, \" = \", resto1_s)\n",
    "    else:\n",
    "        if ind < len(tokenlist):  #fin de la entrada\n",
    "            yyerror(\"en Def\")\n",
    "#fin de Def()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    global ta, toks, tokenlist, ind\n",
    "    lexer = CalcLexer()\n",
    "    toks = CalcLexer.tokens\n",
    "    toks = sorted(toks)\n",
    "    while True:\n",
    "        try:\n",
    "            data = input('data type list > ')\n",
    "        except EOFError:\n",
    "            break\n",
    "        if data:\n",
    "            tokenlist = list(lexer.tokenize(data))\n",
    "            ta = tokenlist[ind]\n",
    "            Def()\n",
    "        ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
