{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: <ipython-input-1-733a45066edb>:133: Symbol 'inicializacion' used, but not defined as a token or a rule\n",
      "ERROR: <ipython-input-1-733a45066edb>:129: Symbol 'condicional' used, but not defined as a token or a rule\n",
      "ERROR: <ipython-input-1-733a45066edb>:125: Symbol 'asignacion' used, but not defined as a token or a rule\n",
      "ERROR: <ipython-input-1-733a45066edb>:121: Symbol 'retorno' used, but not defined as a token or a rule\n",
      "ERROR: <ipython-input-1-733a45066edb>:109: Symbol 'Tipo' used, but not defined as a token or a rule\n",
      "ERROR: <ipython-input-1-733a45066edb>:109: Symbol 'inicializacion' used, but not defined as a token or a rule\n",
      "ERROR: <ipython-input-1-733a45066edb>:109: Symbol 'contenido' used, but not defined as a token or a rule\n",
      "WARNING: Token 'PRINT' defined, but not used\n",
      "WARNING: Token 'NE' defined, but not used\n",
      "WARNING: Token 'OR' defined, but not used\n",
      "WARNING: Token 'NUMBER' defined, but not used\n",
      "WARNING: Token 'WHILE' defined, but not used\n",
      "WARNING: Token 'PLUS' defined, but not used\n",
      "WARNING: Token 'GT' defined, but not used\n",
      "WARNING: Token 'RETURN' defined, but not used\n",
      "WARNING: Token 'IF' defined, but not used\n",
      "WARNING: Token 'NOT' defined, but not used\n",
      "WARNING: Token 'TIMES' defined, but not used\n",
      "WARNING: Token 'DIVIDE' defined, but not used\n",
      "WARNING: Token 'LT' defined, but not used\n",
      "WARNING: Token 'ASSIGN' defined, but not used\n",
      "WARNING: Token 'ELSE' defined, but not used\n",
      "WARNING: Token 'SCANF' defined, but not used\n",
      "WARNING: Token 'AND' defined, but not used\n",
      "WARNING: Token 'LE' defined, but not used\n",
      "WARNING: Token 'GE' defined, but not used\n",
      "WARNING: Token 'INT' defined, but not used\n",
      "WARNING: Token 'MINUS' defined, but not used\n",
      "WARNING: Token 'EQ' defined, but not used\n",
      "WARNING: There are 22 unused tokens\n",
      "ERROR: Infinite recursion detected for symbol 'instruccion'\n",
      "ERROR: Infinite recursion detected for symbol 'funcion'\n"
     ]
    },
    {
     "ename": "YaccError",
     "evalue": "Invalid grammar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mYaccError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-733a45066edb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mPracParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPracLexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sly\\yacc.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(meta, clsname, bases, attributes)\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1585\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1586\u001b[1;33m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sly\\yacc.py\u001b[0m in \u001b[0;36m_build\u001b[1;34m(cls, definitions)\u001b[0m\n\u001b[0;32m   1784\u001b[0m         \u001b[1;31m# Build the underlying grammar object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1785\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__build_grammar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrules\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1786\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mYaccError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid grammar'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[1;31m# Build the LR tables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mYaccError\u001b[0m: Invalid grammar"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "####################################################################\n",
    "#   TRABAJO REALIZADO POR JUAN RUIZ BONALD,RAFAEL ROMAN AGUILAR #\n",
    "###################################################################\n",
    "\n",
    "\n",
    "from sly import Lexer,Parser\n",
    "\n",
    "class PracLexer(Lexer):\n",
    "    # Set of token names.   This is always required\n",
    "    tokens = { NUMBER, ID, WHILE, IF, ELSE, RETURN, SCANF, PRINT,\n",
    "               INT, PLUS, MINUS, TIMES, DIVIDE, ASSIGN,\n",
    "               EQ, LT, LE, GT, GE, NE, AND, OR, NOT}\n",
    "\n",
    "\n",
    "    literals = { '(', ')', '{', '}', ';' }\n",
    "\n",
    "    # String containing ignored characters\n",
    "    ignore = ' \\t'\n",
    "\n",
    "    # Regular expression rules for tokens\n",
    "    PLUS    = r'\\+'\n",
    "    MINUS   = r'-'\n",
    "    TIMES   = r'\\*'\n",
    "    DIVIDE  = r'/'\n",
    "    EQ      = r'=='\n",
    "    ASSIGN  = r'='\n",
    "    LE      = r'<='\n",
    "    LT      = r'<'\n",
    "    GE      = r'>='\n",
    "    GT      = r'>'\n",
    "    NE      = r'!='\n",
    "    AND     = r'&&'\n",
    "    OR      = r'\\|\\|'\n",
    "    NOT     = r'\\!'\n",
    "\n",
    "    @_(r'\\d+')\n",
    "    def NUMBER(self, t):\n",
    "        t.value = int(t.value)\n",
    "        return t\n",
    "\n",
    "    # Identifiers and keywords\n",
    "    ID = r'[a-zA-Z_][a-zA-Z0-9_]*'\n",
    "    ID['if'] = IF\n",
    "    ID['else'] = ELSE\n",
    "    ID['while'] = WHILE\n",
    "    ID['print'] = PRINT\n",
    "    ID['return'] = RETURN\n",
    "    ID['scanf'] = SCANF\n",
    "    ID['int'] = INT\n",
    "\n",
    "    ignore_comment = r'\\#.*'\n",
    "\n",
    "    # Line number tracking\n",
    "    @_(r'\\n+')\n",
    "    def ignore_newline(self, t):\n",
    "        self.lineno += t.value.count('\\n')\n",
    "\n",
    "    def error(self, t):\n",
    "        print('Line %d: Bad character %r' % (self.lineno, t.value[0]))\n",
    "        self.index += 1\n",
    "\n",
    "        \n",
    "class Nodo():\n",
    "    def escribir(self):\n",
    "        pass\n",
    "        \n",
    "class NodoFuncion(Nodo): #Nodo utilizado para las funciones\n",
    "    global f_salida\n",
    "    i = None\n",
    "    def __init__(self, valor):\n",
    "        self.i = valor\n",
    "    def escribirPrincipio(self):\n",
    "        f_salida.write(\".text\\n.globl \", self.i,\"\\n.seh_proc \", self.i,\"\\n\", self.i,\":\\n\" )\n",
    "        \n",
    "        \n",
    "class NodoInic(Nodo): #Nod activado cuando la funci√≥n comienza\n",
    "    global f_salida\n",
    "    def __init__(self):\n",
    "        self.names = { }\n",
    "    def escribirPrologo(self):\n",
    "        f_salida.write(\"pushl %ebp\\nmovl %esp, %ebp\\nsubl $4, %esp\\n\")\n",
    "\n",
    "        \n",
    "class NodoVariables(Nodo): #Nodo activado para almacenar las variables \n",
    "    global f_salida\n",
    "    i = None\n",
    "    j = None\n",
    "    def __init__(self, nombre,valor):\n",
    "        self.i = nombre\n",
    "        self.j = valor\n",
    "    def escribirInic(self):\n",
    "        f_salida.write(\"subl $4, %esp\\n\") #Funcion creada para reservar espacio\n",
    "                                          #cada vez que detectamos una variabe\n",
    "        \n",
    "    def almacenarVariable(self):\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "class PracParser(Parser):\n",
    "    tokens = PracLexer().tokens\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.names = { }\n",
    "        \n",
    "    @_('instruccion entrada')\n",
    "    def entrada(self,p):\n",
    "        pass\n",
    "\n",
    "    @_(' ')\n",
    "    def entrada(self, p):\n",
    "        print(\" \")\n",
    "        \n",
    "    @_('funcion')\n",
    "    def instruccion(self,p):\n",
    "        pass\n",
    "    \n",
    "    @_('Tipo ID \"(\" inicializacion_cabecera \")\" \"{\" contenido \"}\"')\n",
    "    def funcion(self,p):\n",
    "        global inFunction\n",
    "        inFunction = True\n",
    "        nodo = NodoFuncion(p.ID)\n",
    "        nodo.escribirPrincipio()\n",
    "        nodo = NodoInic()\n",
    "        nodo.escribirPrologo()\n",
    "    \n",
    "    \n",
    "    @_('inicializacion \";\"')\n",
    "    def instruccion(self,p):\n",
    "        pass\n",
    "    \n",
    "    @_('Tipo ID Resto_cabecera')\n",
    "    def inicializacion_cabecera(self,p):\n",
    "        pass\n",
    "    \n",
    "    @_('Tipo ID Resto_cabecera')\n",
    "    def inicializacion_cabecera(self,p):\n",
    "        pass\n",
    "    \n",
    "    @_('\",\" Tipo Resto_cabecera')\n",
    "    def Resto_cabecera(self,p):\n",
    "        \n",
    "    \n",
    "    @_('Tipo ID Resto')\n",
    "    def inicializacion(self,p):\n",
    "        global inFunction\n",
    "        nodo = NodoInic()\n",
    "        nodo.escribirInic()\n",
    "        \n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "    @_('retorno \";\"')\n",
    "    def instruccion(self,p):\n",
    "        pass\n",
    "    \n",
    "    @_('asignacion \";\"')\n",
    "    def instruccion(self,p):\n",
    "        pass\n",
    "        \n",
    "    @_('condicional ')\n",
    "    def instruccion(self,p):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    lexer = PracLexer()\n",
    "    parser = PracParser()\n",
    "    \n",
    "    f_entrada = open('main.c','r')\n",
    "    f_salida = open('main.s','x')\n",
    "    \n",
    "    inFunction = False\n",
    "    tablaVarLocal = {}\n",
    "    tablaGlobal = {}\n",
    "    \n",
    "    \n",
    "    text = input('asignacion ');\n",
    "\n",
    "    if text:\n",
    "        parser.parse(lexer.tokenize(text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
